{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HSLjbKuw6FKg"],"authorship_tag":"ABX9TyM6SlP9SgN3OxXbjfVIyLDq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Dependencies"],"metadata":{"id":"HSLjbKuw6FKg"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from concurrent.futures import ThreadPoolExecutor\n","import re"],"metadata":{"id":"yM3AuIrn6Kyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Settings"],"metadata":{"id":"NAA9TpKw6QGV"}},{"cell_type":"code","source":["# funuction to precise the university\n","def dynamic_url_to_scrape(university_id = \"9671583371665794735\"):\n","    return f\"https://scholar.google.com/citations?view_op=view_org&hl=en&org={university_id}&after_author=no-author&astart=0\"\n","\n","def next_page_url(author_id, university_id = \"9671583371665794735\"):\n","    return f\"https://scholar.google.com/citations?view_op=view_org&hl=en&org={university_id}&after_author={author_id}&astart=0\""],"metadata":{"id":"RYE0MD7w6Uee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Proxy setup\n","\n"],"metadata":{"id":"gms5jMRp6tn3"}},{"cell_type":"code","source":["# Proxy API Key\n","PROXY_API_KEY = 'c7b595f3-3772-4ef7-bf62-6f3953308c72'\n","\n","# Function to make requests with proxy rotation\n","def get_page_with_proxy(url):\n","    try:\n","        response = requests.get(\n","            url='https://proxy.scrapeops.io/v1/',\n","            params={\n","                'api_key': PROXY_API_KEY,\n","                'url': url,\n","            },\n","        )\n","        response.raise_for_status()\n","        return response\n","    except requests.exceptions.RequestException as e:\n","        raise Exception(f\"Request failed: {e}\")"],"metadata":{"id":"NmamGE1D68eX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables"],"metadata":{"id":"uIFjzB99-c3t"}},{"cell_type":"code","source":["# crucial variables\n","visited_links = set()\n","visited_after_authors = set()"],"metadata":{"id":"M-4STkLx-hAA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scraping Utils"],"metadata":{"id":"XSDBljlMGLRA"}},{"cell_type":"code","source":["def matching_rule_to_extract_after_author(onclick_text):\n","    match = re.search(r\"window\\.location='([^']+)'\", onclick_text)\n","    if match:\n","        url = match.group(1)\n","\n","        # Decode escaped characters in the URL\n","        url = url.replace('\\\\x3d', '=').replace('\\\\x26', '&')\n","\n","        # Extract the 'after_author' parameter value\n","        after_author_match = re.search(r'after_author=([^&]+)', url)\n","        if after_author_match:\n","            return after_author_match.group(1)\n","    return None"],"metadata":{"id":"1Uh1TpqOGO-S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scrapping functions"],"metadata":{"id":"I5LXTf1y6_pg"}},{"cell_type":"code","source":["def get_next_page(soup, uni_id = None):\n","    if not uni_id:\n","        return None, None\n","    url = None\n","    after_author = None\n","    next_button = soup.find('button', {'aria-label': 'Next'})\n","    if next_button:\n","        onclick_text = next_button.get('onclick')\n","        if onclick_text:\n","            result = matching_rule_to_extract_after_author(onclick_text)\n","            if result:\n","                after_author = result\n","                url = next_page_url(after_author, uni_id)\n","                return url, after_author\n","    return None, None"],"metadata":{"id":"eA4Kkua4RSeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MULTI-THREADING\n","def process_page(soup):\n","    doctor_data = []\n","    doctor_container = soup.find(id=\"gsc_sa_ccl\")\n","    if doctor_container:\n","        doctors = doctor_container.find_all(\"div\", class_=\"gsc_1usr\")\n","        # Use ThreadPoolExecutor to process doctors concurrently\n","        with ThreadPoolExecutor() as executor:\n","            results = list(executor.map(process_doctor, doctors))\n","        # Filter out None results\n","        doctor_data = [doctor for doctor in results if doctor]\n","        df = pd.DataFrame(doctor_data, columns=[\"doctor_id\", \"doctor_name\", \"department\", \"disciplines\", \"publications\", \"citations\", \"reads\"])\n","        df.to_csv(f\"google_scolar_{len(visited_links)}.csv\", index=False)\n","    else:\n","        print(\"Doctor container not found on the page.\")"],"metadata":{"id":"gcHijTIxSALp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_doctor_id(doctor_div):\n","    profile_link_tag = doctor_div.find(\"a\", class_=\"gs_ai_pho\")\n","    if profile_link_tag and profile_link_tag.has_attr(\"href\"):\n","        profile_link = profile_link_tag[\"href\"]\n","\n","        # Use regex to extract the user ID\n","        match = re.search(r\"user=([^&]+)\", profile_link)\n","        if match:\n","            return match.group(1)  # Return the extracted user ID\n","\n","    # Return \"No ID\" if not found\n","    return \"No ID\""],"metadata":{"id":"mcjG-r1pWQGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_doctor_citations(doctor_div):\n","    citations_tag = doctor_div.find(\"div\", class_=\"gs_ai_cby\")\n","    if citations_tag:\n","        citations_text = citations_tag.text.strip()\n","        match = re.search(r'\\d+', citations_text)\n","        if match:\n","            return int(match.group(0))\n","    return 0"],"metadata":{"id":"FzmoO5dWWyzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_doctor_name(doctor_div):\n","  name_tag = doctor_div.find(\"h3\", class_=\"gs_ai_name\")\n","  if name_tag:\n","    return name_tag.text.strip()\n","  else:\n","    return \"No Name\""],"metadata":{"id":"F-tH-Z7dXdT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_disciplines(doctor_div):\n","    disciplines_tag = doctor_div.find(\"div\", class_=\"gs_ai_int\")\n","    if disciplines_tag:\n","        links = disciplines_tag.find_all(\"a\")\n","        if links:\n","            disciplines = [link.text.strip() for link in links]\n","            return \", \".join(disciplines)\n","    return \"\""],"metadata":{"id":"HQ5vF9FKXr5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_doctor(doctor_div):\n","  department = \"Unkown Yet\"\n","  doctor_id =  extract_doctor_id(doctor_div)\n","  citations = extract_doctor_citations(doctor_div)\n","  doctor_name = extract_doctor_name(doctor_div)\n","  disciplines = extract_disciplines(doctor_div)\n","  publications = 0\n","  reads = 0\n","  return doctor_id, doctor_name, department, disciplines, publications, citations, reads"],"metadata":{"id":"REgRWKq_SCJ7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pipeline Utils"],"metadata":{"id":"tXTmweU6AW9x"}},{"cell_type":"code","source":["def finish_scrapping(next_after_author, next_url):\n","  return(next_after_author and next_after_author in visited_after_authors) or (next_url and next_url  in visited_links)"],"metadata":{"id":"lkdFKNxOAZr6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Steps functions"],"metadata":{"id":"Xc2fr4wx8hXT"}},{"cell_type":"code","source":["def traverse_single_page(url, university_id):\n","    print(f\"Visiting {url} *_*\")\n","    response = get_page_with_proxy(url)\n","    visited_links.add(url)\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    process_page(soup)\n","    return get_next_page(soup, university_id)\n","\n","def traverse_pages(url, university_id, MAX_ITERATIONS=None):\n","    if MAX_ITERATIONS and len(visited_links) >= MAX_ITERATIONS:\n","        print(f\"done ^_^ Scraped pages = {MAX_ITERATIONS}\")\n","        return\n","    next_url, next_after_author = traverse_single_page(url, university_id)\n","    if finish_scrapping(next_after_author, next_url):\n","        print(\"done ^_^\")\n","        return\n","    visited_after_authors.add(next_after_author)\n","    traverse_pages(next_url, university_id, MAX_ITERATIONS)"],"metadata":{"id":"KJILG-aK8kOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main function"],"metadata":{"id":"LHMfH4TSMYP6"}},{"cell_type":"code","source":["def start_scraping(university_id = \"9671583371665794735\", pages = None):\n","  if pages:\n","    traverse_pages(dynamic_url_to_scrape(university_id), university_id, pages)\n","  else:\n","    traverse_pages(dynamic_url_to_scrape(university_id), university_id)"],"metadata":{"id":"ctYkxkerMcv7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Scraping"],"metadata":{"id":"HI_saedkMlC1"}},{"cell_type":"code","source":["university_id = \"9671583371665794735\"\n","start_scraping(university_id,pages=2)\n","print(\"thank you !\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrw6D2DXMsBo","executionInfo":{"status":"ok","timestamp":1738566241590,"user_tz":-120,"elapsed":7241,"user":{"displayName":"Ali Assi","userId":"09079658952282962985"}},"outputId":"527317e1-ad08-453c-8583-21ad1cb14a81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Visiting https://scholar.google.com/citations?view_op=view_org&hl=en&org=9671583371665794735&after_author=no-author&astart=0 *_*\n","Visiting https://scholar.google.com/citations?view_op=view_org&hl=en&org=9671583371665794735&after_author=30YeAO_v__8J&astart=0 *_*\n","done ^_^ Scraped pages = 2\n","thank you !\n"]}]}]}